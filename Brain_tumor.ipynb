{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNrlgRaZ3fOU9lbAop7FQDB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PristRawal/Deep_Learning/blob/main/Brain_tumor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hR8X--I_K8iU",
        "outputId": "10a0cdaf-d65c-4642-aa9c-65d5ce44fcc6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import glob\n",
        "import os\n",
        "from torch.utils.data import DataLoader , ConcatDataset\n",
        "from torchvision import datasets, transforms\n",
        "import cv2\n",
        "import sys\n",
        "import math\n",
        "import random\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix"
      ],
      "metadata": {
        "id": "WwiMxDrCQ3QY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(128),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.2482, 0.2485, 0.2486], std=[0.2164, 0.2165, 0.2168]),\n",
        "])"
      ],
      "metadata": {
        "id": "tMf3vFjHQ-4Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tumor = []\n",
        "healthy = []\n",
        "for f in glob.iglob(\"/content/drive/MyDrive/brain_tumor_dataset/yes/*.jpg\"):\n",
        "    img = cv2.imread(f)\n",
        "    img = cv2.resize(img,(128,128))\n",
        "    b, g, r = cv2.split(img)\n",
        "    img = cv2.merge([r,g,b])\n",
        "    tumor.append(img)\n",
        "\n",
        "for f in glob.iglob(\"/content/drive/MyDrive/brain_tumor_dataset/no/*.jpg\"):\n",
        "    img = cv2.imread(f)\n",
        "    img = cv2.resize(img,(128,128))\n",
        "    b, g, r = cv2.split(img)\n",
        "    img = cv2.merge([r,g,b])\n",
        "    healthy.append(img)"
      ],
      "metadata": {
        "id": "95f0TSuqZQ_z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Dataset(object):\n",
        "    \"\"\"An abstract class representing a Dataset.\n",
        "\n",
        "    All other datasets should subclass it. All subclasses should override\n",
        "    ``__len__``, that provides the size of the dataset, and ``__getitem__``,\n",
        "    supporting integer indexing in range from 0 to len(self) exclusive.\n",
        "    \"\"\"\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def __len__(self):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def __add__(self, other):\n",
        "        return ConcatDataset([self, other])"
      ],
      "metadata": {
        "id": "jgdEI9VuZXj6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MRI(Dataset):\n",
        "    def __init__(self):\n",
        "\n",
        "        tumor = []\n",
        "        healthy = []\n",
        "        # cv2 - It reads in BGR format by default\n",
        "        for f in glob.iglob(\"/content/drive/MyDrive/brain_tumor_dataset/yes/*.jpg\"):\n",
        "            img = cv2.imread(f)\n",
        "            img = cv2.resize(img,(128,128)) # I can add this later in the boot-camp for more adventure\n",
        "            b, g, r = cv2.split(img)\n",
        "            img = cv2.merge([r,g,b])\n",
        "            img = img.reshape((img.shape[2],img.shape[0],img.shape[1])) # otherwise the shape will be (h,w,#channels)\n",
        "            tumor.append(img)\n",
        "\n",
        "        for f in glob.iglob(\"/content/drive/MyDrive/brain_tumor_dataset/no/*.jpg\"):\n",
        "            img = cv2.imread(f)\n",
        "            img = cv2.resize(img,(128,128))\n",
        "            b, g, r = cv2.split(img)\n",
        "            img = cv2.merge([r,g,b])\n",
        "            img = img.reshape((img.shape[2],img.shape[0],img.shape[1]))\n",
        "            healthy.append(img)\n",
        "\n",
        "        # our images\n",
        "        tumor = np.array(tumor,dtype=np.float32)\n",
        "        healthy = np.array(healthy,dtype=np.float32)\n",
        "\n",
        "        # our labels\n",
        "        tumor_label = np.ones(tumor.shape[0], dtype=np.float32)\n",
        "        healthy_label = np.zeros(healthy.shape[0], dtype=np.float32)\n",
        "\n",
        "        # Concatenates\n",
        "        self.images = np.concatenate((tumor, healthy), axis=0)\n",
        "        self.labels = np.concatenate((tumor_label, healthy_label))\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.images.shape[0]\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        sample = {'image': self.images[index], 'label':self.labels[index]}\n",
        "\n",
        "        return sample\n",
        "\n",
        "    def normalize(self):\n",
        "        self.images = self.images/255.0"
      ],
      "metadata": {
        "id": "yDZPw5OHgTab"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Custom Dataset-2"
      ],
      "metadata": {
        "id": "uT9Fws_w86WN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import glob\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import transforms\n",
        "\n",
        "class MRI(Dataset):\n",
        "    def __init__(self, transform=None):\n",
        "        self.transform = transform\n",
        "\n",
        "        tumor = []\n",
        "        healthy = []\n",
        "\n",
        "        # Load and preprocess images\n",
        "        for f in glob.iglob(\"/content/drive/MyDrive/brain_tumor_dataset/yes/*.jpg\"):\n",
        "            img = cv2.imread(f)\n",
        "            img = cv2.resize(img, (128, 128))\n",
        "            b, g, r = cv2.split(img)\n",
        "            img = cv2.merge([r, g, b])\n",
        "            img = img.transpose((2, 0, 1))  # Convert to (C, H, W)\n",
        "            tumor.append(img)\n",
        "\n",
        "        for f in glob.iglob(\"/content/drive/MyDrive/brain_tumor_dataset/no/*.jpg\"):\n",
        "            img = cv2.imread(f)\n",
        "            img = cv2.resize(img, (128, 128))\n",
        "            b, g, r = cv2.split(img)\n",
        "            img = cv2.merge([r, g, b])\n",
        "            img = img.transpose((2, 0, 1))  # Convert to (C, H, W)\n",
        "            healthy.append(img)\n",
        "\n",
        "        # Concatenate and create labels\n",
        "        tumor = np.array(tumor, dtype=np.float32)\n",
        "        healthy = np.array(healthy, dtype=np.float32)\n",
        "\n",
        "        tumor_label = np.ones(tumor.shape[0], dtype=np.float32)\n",
        "        healthy_label = np.zeros(healthy.shape[0], dtype=np.float32)\n",
        "\n",
        "        self.images = np.concatenate((tumor, healthy), axis=0)\n",
        "        self.labels = np.concatenate((tumor_label, healthy_label))\n",
        "\n",
        "        # Normalize images\n",
        "        self.images /= 255.0\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image = torch.tensor(self.images[index], dtype=torch.float32)\n",
        "        label = torch.tensor(self.labels[index], dtype=torch.float32)\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        sample = {'image': image, 'label': label}\n",
        "        return sample\n"
      ],
      "metadata": {
        "id": "OB4dtxndh9SV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NN\n"
      ],
      "metadata": {
        "id": "A_9w0Qu79hLF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN,self).__init__()\n",
        "        self.cnn_model = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5),\n",
        "        nn.Tanh(),\n",
        "        nn.AvgPool2d(kernel_size=2, stride=5),\n",
        "        nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5),\n",
        "        nn.Tanh(),\n",
        "        nn.AvgPool2d(kernel_size=2, stride=5))\n",
        "\n",
        "        self.fc_model = nn.Sequential(\n",
        "        nn.Linear(in_features=256, out_features=120),\n",
        "        nn.Tanh(),\n",
        "        nn.Linear(in_features=120, out_features=84),\n",
        "        nn.Tanh(),\n",
        "        nn.Linear(in_features=84, out_features=1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.cnn_model(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc_model(x)\n",
        "        x = F.sigmoid(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "2-pJrC1f950I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# creating a CPU tensor\n",
        "cpu_tensor = torch.rand(10).to(device)\n",
        "# moving same tensor to GPU\n",
        "gpu_tensor = cpu_tensor.to(device)\n",
        "\n",
        "print(cpu_tensor, cpu_tensor.dtype, type(cpu_tensor), cpu_tensor.type())\n",
        "print(gpu_tensor, gpu_tensor.dtype, type(gpu_tensor), gpu_tensor.type())\n",
        "\n",
        "print(cpu_tensor*gpu_tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AFC9YH1499xp",
        "outputId": "e93c9fd5-b6e5-429f-c1cd-ae1d6d084659"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.3929, 0.9876, 0.3490, 0.4831, 0.1236, 0.1572, 0.3624, 0.1019, 0.9483,\n",
            "        0.8157], device='cuda:0') torch.float32 <class 'torch.Tensor'> torch.cuda.FloatTensor\n",
            "tensor([0.3929, 0.9876, 0.3490, 0.4831, 0.1236, 0.1572, 0.3624, 0.1019, 0.9483,\n",
            "        0.8157], device='cuda:0') torch.float32 <class 'torch.Tensor'> torch.cuda.FloatTensor\n",
            "tensor([0.1543, 0.9754, 0.1218, 0.2334, 0.0153, 0.0247, 0.1314, 0.0104, 0.8993,\n",
            "        0.6654], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mri_dataset = MRI()\n",
        "mri_dataset.normalize()\n",
        "device = torch.device('cuda:0')\n",
        "model = CNN().to(device)\n"
      ],
      "metadata": {
        "id": "XyRIB7Yt-HG5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "names={0:'Heathy', 1:'Tumor'}\n",
        "dataloader = DataLoader(mri_dataset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "LrNhIxiu-kBF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "outputs = []\n",
        "y_true = []\n",
        "with torch.no_grad():\n",
        "    for D in dataloader:\n",
        "        image = D['image'].to(device)\n",
        "        label = D['label'].to(device)\n",
        "\n",
        "        y_hat = model(image)\n",
        "\n",
        "        outputs.append(y_hat.cpu().detach().numpy())\n",
        "        y_true.append(label.cpu().detach().numpy())\n"
      ],
      "metadata": {
        "id": "Y8ed07Aj_QNT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = np.concatenate( outputs, axis=0 ).squeeze()\n",
        "y_true = np.concatenate( y_true, axis=0 ).squeeze()"
      ],
      "metadata": {
        "id": "HyNXB82m_W1y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def threshold(scores,threshold=0.50, minimum=0, maximum = 1.0):\n",
        "    x = np.array(list(scores))\n",
        "    x[x >= threshold] = maximum\n",
        "    x[x < threshold] = minimum\n",
        "    return x"
      ],
      "metadata": {
        "id": "6vV3bCl2_eOb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_score(y_true, threshold(outputs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HmtWQzSo_hnD",
        "outputId": "0bf7446f-fcfc-4950-a5d9-74cb1e433acb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3742690058479532"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eta = 0.0001\n",
        "EPOCH = 400\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=eta)\n",
        "dataloader = DataLoader(mri_dataset, batch_size=32, shuffle=True)\n",
        "model.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yLYXizFG_jHs",
        "outputId": "a1f9b654-063d-42ad-f4b9-0b9a2b9729ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNN(\n",
              "  (cnn_model): Sequential(\n",
              "    (0): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
              "    (1): Tanh()\n",
              "    (2): AvgPool2d(kernel_size=2, stride=5, padding=0)\n",
              "    (3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
              "    (4): Tanh()\n",
              "    (5): AvgPool2d(kernel_size=2, stride=5, padding=0)\n",
              "  )\n",
              "  (fc_model): Sequential(\n",
              "    (0): Linear(in_features=256, out_features=120, bias=True)\n",
              "    (1): Tanh()\n",
              "    (2): Linear(in_features=120, out_features=84, bias=True)\n",
              "    (3): Tanh()\n",
              "    (4): Linear(in_features=84, out_features=1, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(1, EPOCH):\n",
        "    losses = []\n",
        "    for D in dataloader:\n",
        "        optimizer.zero_grad()\n",
        "        data = D['image'].to(device)\n",
        "        label = D['label'].to(device)\n",
        "        y_hat = model(data)\n",
        "        # define loss function\n",
        "        error = nn.BCELoss()\n",
        "        loss = torch.sum(error(y_hat.squeeze(), label))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        losses.append(loss.item())\n",
        "    if (epoch+1) % 10 == 0:\n",
        "        print('Train Epoch: {}\\tLoss: {:.6f}'.format(epoch+1, np.mean(losses)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V0on5OK4_mSr",
        "outputId": "8cba3025-cb92-408e-97f1-f539de17c1db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 10\tLoss: 0.664586\n",
            "Train Epoch: 20\tLoss: 0.584413\n",
            "Train Epoch: 30\tLoss: 0.566476\n",
            "Train Epoch: 40\tLoss: 0.543062\n",
            "Train Epoch: 50\tLoss: 0.534169\n",
            "Train Epoch: 60\tLoss: 0.532483\n",
            "Train Epoch: 70\tLoss: 0.510512\n",
            "Train Epoch: 80\tLoss: 0.482020\n",
            "Train Epoch: 90\tLoss: 0.481943\n",
            "Train Epoch: 100\tLoss: 0.461924\n",
            "Train Epoch: 110\tLoss: 0.427665\n",
            "Train Epoch: 120\tLoss: 0.366173\n",
            "Train Epoch: 130\tLoss: 0.352596\n",
            "Train Epoch: 140\tLoss: 0.367166\n",
            "Train Epoch: 150\tLoss: 0.299670\n",
            "Train Epoch: 160\tLoss: 0.328187\n",
            "Train Epoch: 170\tLoss: 0.273022\n",
            "Train Epoch: 180\tLoss: 0.255248\n",
            "Train Epoch: 190\tLoss: 0.219990\n",
            "Train Epoch: 200\tLoss: 0.192756\n",
            "Train Epoch: 210\tLoss: 0.189447\n",
            "Train Epoch: 220\tLoss: 0.158039\n",
            "Train Epoch: 230\tLoss: 0.141209\n",
            "Train Epoch: 240\tLoss: 0.129629\n",
            "Train Epoch: 250\tLoss: 0.093528\n",
            "Train Epoch: 260\tLoss: 0.084833\n",
            "Train Epoch: 270\tLoss: 0.083043\n",
            "Train Epoch: 280\tLoss: 0.059153\n",
            "Train Epoch: 290\tLoss: 0.045941\n",
            "Train Epoch: 300\tLoss: 0.040120\n",
            "Train Epoch: 310\tLoss: 0.037234\n",
            "Train Epoch: 320\tLoss: 0.028193\n",
            "Train Epoch: 330\tLoss: 0.028357\n",
            "Train Epoch: 340\tLoss: 0.020340\n",
            "Train Epoch: 350\tLoss: 0.018059\n",
            "Train Epoch: 360\tLoss: 0.014402\n",
            "Train Epoch: 370\tLoss: 0.011753\n",
            "Train Epoch: 380\tLoss: 0.011463\n",
            "Train Epoch: 390\tLoss: 0.009549\n",
            "Train Epoch: 400\tLoss: 0.008218\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "dataloader = DataLoader(mri_dataset, batch_size=32, shuffle=False)\n",
        "outputs=[]\n",
        "y_true = []\n",
        "with torch.no_grad():\n",
        "    for D in dataloader:\n",
        "        image =  D['image'].to(device)\n",
        "        label = D['label'].to(device)\n",
        "\n",
        "        y_hat = model(image)\n",
        "\n",
        "        outputs.append(y_hat.cpu().detach().numpy())\n",
        "        y_true.append(label.cpu().detach().numpy())\n",
        "\n",
        "outputs = np.concatenate( outputs, axis=0 )\n",
        "y_true = np.concatenate( y_true, axis=0 )"
      ],
      "metadata": {
        "id": "49rOh4w7_oRU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_score(y_true, threshold(outputs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wOSH0zKW_yG2",
        "outputId": "0c3cf857-7247-4921-8aa3-835d0ab2ff7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Qz7alL9n_z6e"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}