{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1zETXtHCQ22OMeHaxgMUa-5h4JSCZ0L_n",
      "authorship_tag": "ABX9TyO3oY43ooESXfQSoGU9Rt+X",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PristRawal/Deep_Learning/blob/main/Unet_Car.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TVCCdWYWr2UH"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from albumentations import Compose, Resize, Normalize\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from PIL import Image\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CarvanaDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, image_dir, mask_dir, transform=None):\n",
        "        self.image_dir = image_dir\n",
        "        self.mask_dir = mask_dir\n",
        "        self.transform = transform\n",
        "        self.images = os.listdir(image_dir)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img_path = os.path.join(self.image_dir, self.images[index])\n",
        "        mask_path = os.path.join(self.mask_dir, self.images[index].replace(\".jpg\", \"_mask.gif\"))\n",
        "        image = np.array(Image.open(img_path).convert(\"RGB\"))\n",
        "        mask = np.array(Image.open(mask_path).convert(\"L\"), dtype=np.float32)\n",
        "        mask[mask == 255.0] = 1.0\n",
        "\n",
        "        if self.transform is not None:\n",
        "            transformed = self.transform(image=image, mask=mask)\n",
        "            image = transformed[\"image\"]\n",
        "            mask = transformed[\"mask\"]\n",
        "\n",
        "        return image, mask\n"
      ],
      "metadata": {
        "id": "y0aya4u6sAXa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from albumentations import Compose, Resize, Normalize\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "transform = Compose([\n",
        "    Resize(256, 256),\n",
        "    Normalize(mean=(0.0, 0.0, 0.0), std=(1.0, 1.0, 1.0)),\n",
        "    ToTensorV2(),\n",
        "])\n"
      ],
      "metadata": {
        "id": "297Gpe0FsEF-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = CarvanaDataset(\n",
        "    image_dir='/content/drive/MyDrive/Car/Car_Train_Final',\n",
        "    mask_dir='/content/drive/MyDrive/Car/Car_trainmask_Final',\n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n"
      ],
      "metadata": {
        "id": "6tHrwKN5sGq5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DoubleConv(nn.Module):\n",
        "    def __init__(self,in_channels,out_channels):\n",
        "      super(DoubleConv, self).__init__()\n",
        "      self.double_conv = nn.Sequential (\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "      return self.double_conv(x)\n",
        "class Down(nn.Module):\n",
        "    \"\"\"Downscaling with maxpool then double conv\"\"\"\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(Down, self).__init__()\n",
        "        self.maxpool_conv = nn.Sequential(\n",
        "            nn.MaxPool2d(2),\n",
        "            DoubleConv(in_channels, out_channels)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.maxpool_conv(x)\n",
        "class Up(nn.Module):\n",
        "    \"\"\"Upscaling then double conv\"\"\"\n",
        "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
        "        super(Up, self).__init__()\n",
        "\n",
        "        if bilinear:\n",
        "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "            self.conv = DoubleConv(in_channels, out_channels)\n",
        "        else:\n",
        "            self.up = nn.ConvTranspose2d(in_channels // 2, in_channels // 2, kernel_size=2, stride=2)\n",
        "            self.conv = DoubleConv(in_channels, out_channels)\n",
        "\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        x1 = self.up(x1)\n",
        "\n",
        "        # crop x2 to x1 size (U-Net uses 'copy and crop')\n",
        "        diffY = x2.size()[2] - x1.size()[2]\n",
        "        diffX = x2.size()[3] - x1.size()[3]\n",
        "        x2 = x2[:, :, diffY // 2:x2.size()[2] - diffY // 2,\n",
        "                     diffX // 2:x2.size()[3] - diffX // 2]\n",
        "\n",
        "        x = torch.cat([x2, x1], dim=1)\n",
        "        return self.conv(x)\n",
        "\n",
        "class OutConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(OutConv, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, n_channels=1, n_classes=2, bilinear=True):\n",
        "        super(UNet, self).__init__()\n",
        "        self.n_channels = n_channels\n",
        "        self.n_classes = n_classes\n",
        "        self.bilinear = bilinear\n",
        "\n",
        "        self.inc = DoubleConv(n_channels, 64)\n",
        "        self.down1 = Down(64, 128)\n",
        "        self.down2 = Down(128, 256)\n",
        "        self.down3 = Down(256, 512)\n",
        "        self.down4 = Down(512, 1024)\n",
        "\n",
        "        # Correct the bottleneck input channels\n",
        "        self.bottleneck = DoubleConv(1024, 1024) if bilinear else DoubleConv(512, 1024)\n",
        "\n",
        "\n",
        "        self.up1 = Up(1024 + 512, 512, bilinear)\n",
        "        self.up2 = Up(512 + 256, 256, bilinear)\n",
        "        self.up3 = Up(256 + 128, 128, bilinear)\n",
        "        self.up4 = Up(128 + 64, 64, bilinear)\n",
        "\n",
        "        self.outc = OutConv(64, n_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.inc(x)       # 64\n",
        "        x2 = self.down1(x1)    # 128\n",
        "        x3 = self.down2(x2)    # 256\n",
        "        x4 = self.down3(x3)    # 512\n",
        "        x5 = self.down4(x4)    # 1024\n",
        "\n",
        "        x5 = self.bottleneck(x5)\n",
        "\n",
        "        x = self.up1(x5, x4)\n",
        "        x = self.up2(x, x3)\n",
        "        x = self.up3(x, x2)\n",
        "        x = self.up4(x, x1)\n",
        "        logits = self.outc(x)\n",
        "        return logits"
      ],
      "metadata": {
        "id": "ZbUSrkitsags"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = UNet(n_channels=3, n_classes=1).to('cuda')\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n"
      ],
      "metadata": {
        "id": "Ocyp-v7TsRAh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dice_score(preds, targets, threshold=0.5):\n",
        "    preds = torch.sigmoid(preds)\n",
        "    preds = (preds > threshold).float()\n",
        "    intersection = (preds * targets).sum(dim=(1, 2, 3))\n",
        "    union = preds.sum(dim=(1, 2, 3)) + targets.sum(dim=(1, 2, 3))\n",
        "    dice = (2. * intersection + 1e-8) / (union + 1e-8)\n",
        "    return dice.mean().item()\n",
        "\n",
        "def iou_score(preds, targets, threshold=0.5):\n",
        "    preds = torch.sigmoid(preds)\n",
        "    preds = (preds > threshold).float()\n",
        "    intersection = (preds * targets).sum(dim=(1, 2, 3))\n",
        "    union = ((preds + targets) >= 1).float().sum(dim=(1, 2, 3))\n",
        "    iou = (intersection + 1e-8) / (union + 1e-8)\n",
        "    return iou.mean().item()\n"
      ],
      "metadata": {
        "id": "S0UK1e1VshnR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_fn(loader, model, optimizer, loss_fn, device):\n",
        "    model.train()\n",
        "    loop = tqdm(loader, desc=\"Training\", leave=False)\n",
        "\n",
        "    total_loss = 0.0\n",
        "    total_dice = 0.0\n",
        "    total_iou = 0.0\n",
        "\n",
        "    for data, targets in loop:\n",
        "        data = data.to(device)\n",
        "        targets = targets.to(device).unsqueeze(1)  # [B, 1, H, W]\n",
        "\n",
        "        preds = model(data)\n",
        "        loss = loss_fn(preds, targets)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        total_dice += dice_score(preds, targets)\n",
        "        total_iou += iou_score(preds, targets)\n",
        "\n",
        "        loop.set_postfix(loss=loss.item())\n",
        "\n",
        "    n = len(loader)\n",
        "    return total_loss / n, total_dice / n, total_iou / n\n"
      ],
      "metadata": {
        "id": "EBdEmQTzs6kU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_fn(loader, model, loss_fn, device):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    total_dice = 0.0\n",
        "    total_iou = 0.0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        loop = tqdm(loader, desc=\"Validating\", leave=False)\n",
        "        for data, targets in loop:\n",
        "            data = data.to(device)\n",
        "            targets = targets.to(device).unsqueeze(1)\n",
        "\n",
        "            preds = model(data)\n",
        "            loss = loss_fn(preds, targets)\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            total_dice += dice_score(preds, targets)\n",
        "            total_iou += iou_score(preds, targets)\n",
        "\n",
        "            loop.set_postfix(val_loss=loss.item())\n",
        "\n",
        "    n = len(loader)\n",
        "    return total_loss / n, total_dice / n, total_iou / n\n"
      ],
      "metadata": {
        "id": "6FkZHFQjtPG9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model = UNet(n_channels=3, n_classes=1).to(device)\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "# Datasets\n",
        "train_dataset = CarvanaDataset(image_dir='/content/drive/MyDrive/Car/Car_Train_Final', mask_dir='/content/drive/MyDrive/Car/Car_trainmask_Final', transform=transform)\n",
        "val_dataset = CarvanaDataset(image_dir='/content/drive/MyDrive/Car/Validation_img', mask_dir='/content/drive/MyDrive/Car/Validation_mask', transform=transform)\n",
        "\n",
        "# DataLoaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False)\n",
        "\n",
        "# Epochs\n",
        "epochs = 5\n",
        "for epoch in range(epochs):\n",
        "    print(f\"\\nEpoch [{epoch+1}/{epochs}]\")\n",
        "\n",
        "    train_loss, train_dice, train_iou = train_fn(train_loader, model, optimizer, criterion, device)\n",
        "    val_loss, val_dice, val_iou = eval_fn(val_loader, model, criterion, device)\n",
        "\n",
        "    print(f\"Train Loss: {train_loss:.4f} | Dice: {train_dice:.4f} | IoU: {train_iou:.4f}\")\n",
        "    print(f\"Val   Loss: {val_loss:.4f} | Dice: {val_dice:.4f} | IoU: {val_iou:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "kLPIE1zvtP73",
        "outputId": "611b2ac3-2654-4d08-f54d-8f47deadadb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch [1/5]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'eval_fn' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-11-1233438449.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iou\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_iou\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Train Loss: {train_loss:.4f} | Dice: {train_dice:.4f} | IoU: {train_iou:.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'eval_fn' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Plottings"
      ],
      "metadata": {
        "id": "XmnvImikeNKM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), '/content/drive/MyDrive/unet_model.pth')"
      ],
      "metadata": {
        "id": "9LBazIwzcPlc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}